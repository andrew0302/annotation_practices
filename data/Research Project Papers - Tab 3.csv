DS Descriptor,DS DOI,DS Citation,Done for?,Empty,Outcome,Human Labels,OG Labels,Label Source,Prescreening,Compensation,Training,Formal Instructions,Labeller Population Rationale,Total Labellers,Annotators per item,Label Threshold,Overlap,Overlap Synthesis,Synthesis Type,Discussion,IRR,Metric,Item Population,Item Population Rationale,Item Source,a Priori Sample Size,Item Sample Size Rationale,a Priori Annotation Schema,Annotation Schema Rationale,Link to Data,Notes,Additional Links,
PASCAL VOC 2012,10.48550/arXiv.1902.06162,136836,TPAMI,No,Physical classification,Yes for all,OG,Annotators,Unknown,No information,Some training,Formal instructions,No information,20,No information,No information,"Yes, for all",Quantitative,Discussion,Yes,No,"crowdsourcing proved low quality, then an annotator labelled and another one verified.",Unsure,"realistic population (images are pictures made by photographers), 4 intuitive categories (person, animal, vehicle, indoor), 50/50 training and testing",Flickr,No information,No information,No information,No information,Yes,"paper is from 2015, I had to externally search for it to find relevant information. the official page of PASCAL VOC 2012 does not really offer information.",https://link.springer.com/article/10.1007/s11263-014-0733-5,
PASCAL VOC 2007,10.1007/s11263-009-0275-4,361678,TPAMI,No,Physical classification,Yes for all,OG,Annotators,Unknown,No information,Some training,Formal instructions,No information,No information,No information,No information,Unsure,No information,No information,Yes,No,No information,500000,"4 groups of data (vehicles, animals, 
household objects and people), semantic and visual similarity, harder to make a distinction between ""bus"" and ""motorcycle""",Flickr,20,"44269 images were considered from the half a mil, the rest being discarded as either not part of the categories or unsuitable",No information,No information,No,"well structured paper, dataset is available on kaggle with an easy search",https://paperswithcode.com/dataset/pascal-voc-2007,
ImageNet,10.1109/CVPR.2009.5206848,163176,AAAI,No,"""Object recognition, image classification and automatic object clustering""",Yes for all,OG,MTurk,Unknown,Money,No information,Unsure,No information,No information,No information,Dynamically determined based on a confidence score they calculate,"Yes, for some",Quantitative,Majority vote,No information,No information,No information,Images on the Internet,No information,"Queries from ""several image search engines"" in different languages",No,No information,WordNet synsets are used as labels,WordNet provides a good ontological structure,Yes,,https://www.image-net.org,
Pascal Context,10.1109/CVPR.2014.119,35553,TPAMI,No,Physical classification,Yes for all,OG,Annotators,Unknown,No information,No information,No information,No information,6,No information,No information,"Yes, for all",Other,Each image labelled once and then double checked by one of the organizers.,Yes,No,No information,10103,Ensure continuity with the community benchmark.,PASCAL VOC 2010,Simply annotate entire PASCAL VOC 2010,No information,No information,"Push beyond earlier benchmarks (e.g. Barcelona, SUN, Sift Flow. Higher class entropy and far more varied ""stuff"" pixels.",Yes,"extension of PASCAL VOC 2010, densely labeled semantic-segmentation dataset.",,
Cityscapes,10.1109/CVPR.2016.350,59688,TPAMI,No,Physical classification,Yes for all,OG,Professional Annotators,Unknown,No information,Some training,Formal instructions,No information,No information,1 annotator per image (and two for the 30-image overlap set),No information,"Yes, for all",No information,A subset of 30 fine-annotated images were indepdendently labeled twice.,No,Yes,Percentage of pixels with identical class labels.,5000 fine-annotated images + 20000 coarse-annotated images.,"Fine set: selected from 27 of the 50 cities to maximize diversity in foreground objects, backgrounds and scene layouts. Coarse set: one frame every 20s or 20m of driving in the remaining cities.","Video recorded from a moving vehicle in 50 cities (Germany and neighbours), capturing spring to fall conditions.",5000 fine and 20000 coarse annotations.,"Balance between annotation cost (1.5h per image for fine, less than 7m for coarse)",30 classes fixed before annotation began.,"Classes chosen based on frequency in street scenes, application relevance, annotation cost and compatibility with existing datasets.",Yes,"Includes stereo depth, vehicle odometry, outside temperature and GPS tracks.",Annotation tool was to be released upon dataset publication.,
sun rgb-d,10.1109/CVPR.2015.7298655,15458,TPAMI,No,Physical classification,Yes for all,OG,"2D polygons from MTURK, 3D boxes & room layouts by 18 trained contractors",Project Specific,Money,Some training,Formal instructions,No information,"18 oDesk contractors, AMT worker count unspecified.",1,"2D: >=6 polygons, >=80% total coverage, >=30% small polygon coverage",No information,Not applicable,No information,No,No,No information,"10335 RGB-D images, 3784 Kinect v2, 1159 Intel RealSense, 1449 NYU Depth v2, 554 B3DO, 3389 SUN3D","Achieve PASCAL VOC scale, enable cross-sensor generalization studies, broad indoor scene coverage.","Manual capturing + subset of existing NYU, B3DO, SUN3D videos",10000 images target.,"Support deep learning, avoid overfitting, study cross-sensor bias, balance cost and time.","Object & scene category lists fixed before: 800 object classes, 47 scene classes.",Designed to match PASCAL-scale dataset sizes and support 3D vision tasks.,Yes,"Includes detailed sensor calibration, depth-map fusion algo and 3D alignment methods.",,
conll-2003,N/A,86025,ACL,No,Named entity recognition,Yes for some,OG,"Annotators - ""done by hand at the University of Antwerp.""",Unknown,No information,No information,Formal instructions,No information,No information,No information,No information,No information,No information,No information,No information,No,No information,611739 annotated tokens,No information,"News stories (Reuters Corpus, Frankfurter Rundshau)",No,No,Mostly external (MUC),External,Yes,"Link to original dataset was broken, but it was easily accessible from other source; criminally low amount of information given about annotation process",,
English Wikipedia,N/A,93234,ACL,No,Pretraining,No / machine labelled,Not Labelled,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,"Varying, but over 1 billion tokens",No information,Wikipedia,Usually used the latest dump to get most tokens,No information,Not applicable,Not applicable,No,Papers using English wikipedia generally don't provide a direct link to the dump or query and don't provide the exact date downloaded (preprocessing is also rarely specified),,
squad,10.18653/v1/D16-1264,66941,ACL,No,Reading comprehension,Yes for all,OG,MTurk,Unsure,Money,No information,Formal instructions,No information,No information,"Unsure (1 prolly, but not mentioned specifically)",No infromation,No,Not applicable,Not applicable,No,No,Not applicable,107785,Obtain high quality by taking samples from top 10000 articles,Wikipedia,No,No,No,"Yes, good rationale",,,,
bookcorpus,10.1109/ICCV.2015.11,45687,ACL,No,Align movies and books,No / machine labelled,Not Labelled,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,"984,846,357 words",No information,Web,No,No,Not applicable,Not applicable,"Yes, but broken","Books were collected from web, but unspecified from where. 16 genres mentioned but not named specifically",,
COCO,10.1007/978-3-319-10602-1_48,405018,CVPR,No,Object recognition,Yes for all,OG,MTurk,Project Specific,Money,Some training,Formal instructions,No information,No information,5 annotators for labeling stage,No information,"Yes, for all",Quantitative,Majority vote,No,No,Not applicable,Images of complex everyday scenes with common objects,"Aimed for non-iconic, context-rich scenes to improve generalization.",Flickr,No information,No information,Hierarchical categorization,"subset of the most frequently used words that denote visually identifiable objects, children 4 to 8 years old",Yes,,,
CIFAR-10,N/A,383711,AAAI,No,Object recognition,Yes for all,OG,Students with no claim of expertise,Unknown,Money,No information,Formal instructions,No information,No information,1,1,No,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Images of objects,To improve on the 80 Million Tiny Images dataset,80 Million Tiny Images dataset (DOI: 10.1109/TPAMI.2008.128),No information,No information,10 classes,No information,No,,,
CIFAR-100,N/A,28933,AAAI,No,Object recognition,Yes for all,OG,Students with no claim of expertise,Unknown,Money,No information,Formal instructions,No information,No information,1,1,No,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Images of objects,To improve on the 80 Million Tiny Images dataset,80 Million Tiny Images dataset (DOI: 10.1109/TPAMI.2008.128),No information,No information,100 classes,"Chosen to be mutually exclusive with CIFAR-10. Otherwise, no information.",No,,,
Arcade Learning Environment,10.48550/arXiv.1207.4708,6782,AAAI,No,"""Empirically assessing agents designed for general competency"" p. 2",No / machine labelled,Not Labelled,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Atari 2600 games,"Yes, as the researchers considered it a suitable benchmark for contemporary reinforcement learning algorithms",Stella - an open-source Atari 2600 emulator,All Atari 2600 games at the time (over 500),To provide a diverse set of challenges,Not applicable,Not applicable,"Yes, but broken",Emulator of Atari 2600 games,,
Mnist,10.1109/5.726791,121570,TPAMI,No,Digit classification.,Yes for all,OG,High-school students and Census Bureau employees.,Unknown,No information,No information,Formal instructions,Assumes writer's intended digit is correct label; ambiguous inputs are included.,"500 writers for SD-1, SD-3 not mentioned.",1,No information,No,Not applicable,No information,No information,No information,No information,60000 training + 10000 test,Mixed SD-1 and SD-3 to ensure robustness,NIST Special Database 1 (SD-1) and SD-3,Targetted large dataset to match a scale suitable for NN.,No,Digit classes fixed.,Standard,"Yes, but broken","MNIST built on NIST, three versions exist (regular, deslanted and 16x16)",,
Kinetics,10.48550/arXiv.1705.06950,13117,AAAI,No,Human action classification,Yes for all,OG,MTurk,Unknown,Money,No information,Formal instructions,No information,No information,3-5,3,"Yes, for all",Quantitative,Majority vote,No information,No information,Not applicable,All videos depicting human actions,Provides a broad range of videos,YouTube,No,No information,Mostly yes. The human actions were taken from external sources but updated if the category was irrelevant.,The researchers wanted to provide a broad domain of human actions.,"Yes, but broken","The dataset paper contains a whole section on discussing possible biases in the dataset, which is a bonus",,
bsds500,10.1109/TPAMI.2010.161,20619,TPAMI,No,Countour and region evaluation,Yes for all,OG,Annotators,Unknown,No information,No information,Some Instructions,No information,No information,5,No information,"Yes, for all",Other,Annotations remain separate for evaluation.,No information,Yes,F Measure,500 images (BSDS300 + 200 addiutional),Capture a wide variety of natural scenes.,"original BSDS, exact source not mentioned.",No information,No information,No information,No information,No,"Worst dataset paper so far, has multiple ground truths per image.",,
ImageNet 2012,10.48550/arXiv.1409.0575,430868,CVPR,No,Image classification; single-object detection,Yes for all,OG,MTurk,Unknown,Money,Some training,Formal instructions,Mix of crowd and expert labellers; experts used for evaluation,No information,Dynamic per image,Confidence threshold,"Yes, for all",Quantitative,Majority vote and confidence score table,No,No information,No information,Internet images,Designed for coverage and diversity with synets,"Search engines, Flickr, scene-based queries","No information, goal of maximum coverage","As much as we could, with budget constraints",Categories from WordNet,Wordnet structure provides semantic grounding; adjusted for ambiguity,Yes,"Other years are mentioned in this paper, only a few details are differing between ILSVRC 2010-2014",https://www.image-net.org,
ILSVRC 2014,10.48550/arXiv.1409.0575,49723,CVPR,No,Image classification; object detection,Yes for all,OG,MTurk,Unknown,Money,Some training,Formal instructions,Mix of crowd and expert labellers; experts used for evaluation,No information,"Dynamic per image, at least 10",Confidence threshold,"Yes, for all",Quantitative,Majority vote and confidence score table,No,No information,No information,Internet images,Designed for coverage and diversity with synets,"Search engines, Flickr, scene-based queries","No information, goal of maximum coverage","As much as we could, with budget constraints",Categories from WordNet,Wordnet structure provides semantic grounding; adjusted for ambiguity,Yes,"Other years are mentioned in this paper, only a few details are differing between ILSVRC 2010-2014",https://www.image-net.org,
people-art,10.48550/arXiv.1505.00110,38749,CVPR,No,Object detection,Yes for all,OG,Reasearchers,Unknown,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,Not applicable,Images depicting people in a wide range of artistic styles.,People are one of the most consistently represented classes across artistic depictions,43 styles from WikiPaintings.org; 1 cartoon style via Google; 1 photographic style from PASCAL VOC2012.,No information,As many as the authors could annotate,No information,No information,No,literally 3 paragraphs about the dataset,,
multi-nli,10.18653/v1/N18-1101,16073,ACL,No,NLI,Yes for all,OG,Hybrid,No prescreening (stated),Money,No information,Formal instructions,No information,387,1 ( then 4 second round),1 ( then 4 second round ),"Yes, for some",Quantitative,"Majority vote, discarded if no majority",No,No,Not applicable,432702 sentence pairs,Approximate the way modern english is used and have a diverse corpus; avoid books that are too difficult of annotators,Open American National Corpus; Gutenberg,No information,No information,Similar to SNLI,"Yes, good rationale",Yes,"quite decent, not much background on annotators though",,
inria person,10.1109/CVPR.2005.177,11450,TPAMI,No,Pedestrian classification,Yes for all,OG,Personal photo collection.,Unknown,Not applicable,No information,No information,No information,No information,1,No information,No,Not applicable,No information,No information,No information,Not applicable,"1805 positive (person), 12180 negative (background)","PASCAL scale, diverse poses and backgrounds, exceeding MIT pedestrian set.","Positive: varied personal photos, negative random crops from person-free images.","~1800 positive examples, roughly double the existing MIT pedestrian training set.",Ensure sufficient data for training SVM models.,"Class labels ""person"" vs ""background""",Chosen to support SVM.,Yes,"does not really provide any info, kinda bad",,
CoLA,10.48550/arXiv.1805.12471,89,ACL,No,Linguistic Acceptability,Yes for all,External,Linguistic Publications,Not applicable,Not applicable,Not applicable,Not applicable,"Yes, good rationale",No information,1,1,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,10657,Wanted linguistics fenomena,Linguistic Publications,No information,No information,No,Boolean label since linguists design items to be annotated in a binary way,Yes,They had a validation round as well to make sure the collected labels aligned with expert judgement,,
SST-2,N/A,8987,ACL,No,sentiment analysis,Yes for all,OG,MTurk,Unknown,Money,No information,Formal instructions,No information,No information,3,3,"Yes, for all",Qualitative,Average,No,No,Not applicable,215154 phrases,No information,Sentiment scale dataset,No information,No information,No,Yes - Boolean labels are not enough,"Yes, but broken",SST-2 is the binary version of SST - this information was not straightforward to find; supplimentary material did not provide much more information; No clarification on how the sentences were split,,
Picasso,10.48550/arXiv.1409.6235,38749,CVPR,No,Human figure detection,Yes for some,Not Labelled,Individual annotators,No prescreening (stated),Money,Not applicable,Formal instructions,No information,18,14-15 per image,No information,"Yes, for all",Quantitative,Median of bounding box corners,No,Yes,F1 score,Picasso depicting people,Chosen to evaluate perception under extreme abstraction,Digitaized Picasso paintings,No information,All Cubist paintings containing a human subject,Focused on person figure bounding boxes; abstraction also rated.,Designed to assess both detection and abstraction rating.,No,They collected abstraction scores for each painting,,
Places,10.1109/TPAMI.2017.2723009,39578,CVPR,No,Scene classification,Yes for all,OG,MTurk,"Generic Skill Based, No prescreening (stated)",Money,Some training,Formal instructions,No information,No information,>=2,Initial round had default NO; YES required keypress. Second round had default YES.,"Yes, for some",Other,"YES/NO 2 times, then third round classifier + MTurk",No,No information,No information,Scene photographs of places where a human could fit,"Aimed to exhaustively cover “places a human can be in,” using functional and perceptual criteria.","Google, Bing, and Flickr image search; expanded queries with 696 adjectives","minimum 5,000 per category, aiming for millions overall.",To support CNN training and maximize diversity; added more where needed via classifier bootstrapping.,SUN category ontology from WordNet guided scene definitions,"Defined categories to reflect spatial, functional, and linguistic distinctiveness of environments.",Yes,,,
PEMS03,10.1609/aaai.v34i01.5438,1786,AAAI,No,Traffic flow prediction,No / machine labelled,Not Labelled,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Traffic information in California,No information,"PeMS, taken from presumably District 3","Yes, 358 sensors in 9/1/2018 - 11/30/2018",No information,Not applicable,Not applicable,No,"Very badly defined dataset. The data is retrieved from PeMS - a measurement system for traffic in California. The authors provide the granularity of the data. However, the district is very vaguely specified - it is not clear if the number 03 refers to the district 3 or not. Additionally, there is no specification on which sensors they chose.",Link to PeMS: https://pems.dot.ca.gov/. DOI of PeMS paper: 10.3141/1811-08.,
PEMS04,10.1609/aaai.v34i01.5438,1978,AAAI,No,Traffic flow prediction,No / machine labelled,Not Labelled,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Traffic information in California,No information,"PeMS, taken from presumably District 4","Yes, 307 sensors in 1/1/2018 - 2/28/2018",No information,Not applicable,Not applicable,No,Check note for PEMS03. Same applies for this dataset.,Link to PeMS: https://pems.dot.ca.gov/. DOI of PeMS paper: 10.3141/1811-08.,
PEMS07,10.1609/aaai.v34i01.5438,1978,AAAI,No,Traffic flow prediction,No / machine labelled,Not Labelled,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Traffic information in California,No information,"PeMS, taken from presumably District 7","Yes, 883 sensors in 5/1/2017 - 8/31/2017",No information,Not applicable,Not applicable,No,Check note for PEMS03. Same applies for this dataset.,Link to PeMS: https://pems.dot.ca.gov/. DOI of PeMS paper: 10.3141/1811-08.,
PEMS08,10.1609/aaai.v34i01.5438,1978,AAAI,No,Traffic flow prediction,No / machine labelled,Not Labelled,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Traffic information in California,No information,"PeMS, taken from presumably District 8","Yes, 170 sensors in 7/1/2016 - 8/31/2016",No information,Not applicable,Not applicable,No,Check note for PEMS03. Same applies for this dataset.,Link to PeMS: https://pems.dot.ca.gov/. DOI of PeMS paper: 10.3141/1811-08.,
ICDAR2015-Challenge-4,10.1109/ICDAR.2015.7333942,2018,AAAI,No,Incidental scene text detection,Yes for all,OG,APEP-te platform,Unknown,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,Scenes with incidental text,Unsure,Photographs taken,No information,No information,Yes,Yes,No,,,
caltech101,10.22002/D1.20086,26156,TPAMI,No,Physical classification,Yes for all,OG,Human Annotators,Unknown,Unsure,No information,No information,No information.,3,No information,No information,No information,No information,Not applicable,No information,No information,No information.,101 categories with about 40 to 800 images (most categories have about 50 images),No information,Google Image Search,No information,No information,No information.,"Flipping through the pages of the Webster Collegiate Dictionary, picking categories that were associated with a drawing.",Yes,"Close to no data, there is another paper that talks about the dataset",https://ieeexplore-ieee-org.tudelft.idm.oclc.org/stamp/stamp.jsp?tp=&arnumber=1384978,
msrc 21,10.1007/s11263-007-0109-1,8295,TPAMI,No,Physical classification,Yes for all,OG,Human Annotators,Unknown,No information,No information,No information,No information.,No information.,No information.,No information.,No information,No information,Not applicable,No information,No information,No information.,591 photographs,No information,No information,21 object classes,"No information, but images picked so there is general liughting, camera viewpoint, scene geometry, object pose and articulation.",No information.,No information.,Yes,"This dataset requires discussion, I am not sure I found the right one.",https://www.microsoft.com/en-us/research/project/image-understanding/downloads/,https://link.springer.com/chapter/10.1007/11744023_1
nyudv2,10.1007/978-3-642-33715-4_54,37507,TPAMI,No,,Yes for all,OG,MTurk,Unknown,No information,No information,No information,MTurk to obtain dense per-pixel labelling,No information.,No information,No information,No information,No information,Not applicable,No information,No information,No information.,"1449 RGB-D images from 435103 video frames, captured in 3 U.S cities",Hand selected images to ensure diverse scene content and lack of similarity,Kinect v1 in-house; indoor commercial and residential buildings,No information,Diverse scene,"894 object categories; 26 scene classes, 4 structure classes",No information,Yes,Too much focus on algorithmic solution,,
MRPC,https://aclanthology.org/I05-5002/,6309,ACL,No,Paraphrase detection,Yes for all,OG,Butler Hill Group,Unknown,No information,No information,Some Instructions,No information,3,No information,2,"Yes, for all",Quantitative,Third annotator judges,No information,Yes,No information,5801 sentence pairs,Likely to yield positive examples,"Web, news articles selected by a classifier to be similar",No information,No information,No,Discovered through trial and error that keeping it simple was best,"Yes, but broken","Nice method to select data to be labelled, not much said about annotators",,
PASCAL VOC 2011,N/A,25035,CVPR,No,"Object detection, classification, segmentation, and action classification in images",Yes for all,OG,Reasearchers and volunteers,Unknown,No information,No information,Formal instructions,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,Real-world photographs of scenes with annotated objects (20 categories),"To provide varied, real-world examples for object detection and segmentation tasks",Flickr and other photo-sharing websites,"Yes, 28952",Aimed to provide sufficient data for training and evaluating object recognition models.,Yes,The schema was designed to facilitate object detection and segmentation tasks.,Yes,"this is not based on the paper, but the link, there is a paper introducing the development kit",http://host.robots.ox.ac.uk/pascal/VOC/voc2011/devkit_doc.pdf,
nuScenes,10.1109/CVPR42600.2020.01164,4485,AAAI,No,Multimodal Dataset for Autonomous Driving,Yes for all,OG,Experts,Unknown,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,Driving recording made by the researchers in Boston and Singapore,"""Diversity across locations in terms of vegetation, buildings, vehicles, road markings and right versus left-hand traffic"" with driving routes that are ""are carefully chosen to capture a diverse set of locations (urban, residential, nature and industrial), times (day and night) and weather conditions (sun, rain and clouds).",Cameras and sensors mounted on a Renault Zoe,Yes - 1000 scenes,No information,Yes,No information,Yes,The dataset was very careful and transparent as to how to collect the data but was not very careful and transparent as to how to annotate it,https://github.com/nutonomy/nuscenes-devkit,
STSb,10.48550/arXiv.1708.00055,8110,ACL,No,Semantic Textual Similarity,Implicit Yes,No information,No information,Unknown,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No,Collection of data form previous editions of SenEval,,
qqp,N/A,1801,ACL,No,Paraphrase detection,Unknown,OG,No information,Unknown,No information,No information,No information,No information,No information,No information,No information,No information,Not applicable,Not applicable,No information,No information,Not applicable,400000 question pairs,No information,Quora,No information,No information,No,"Yes, need to know whether questions is semantically equivalent or not",Yes,No information is given about annotation,,
LOL,10.48550/arXiv.1808.04560,2306,AAAI,No,Low light image enhancement,Yes for some,OG,Paper's authors,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,No information,1,1,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Images of real-world scenes,"So as to capture ""degradation features and properties"" of real world images",Photos were taken by the authors,500,No information,Not applicable,Not applicable,No,"Dataset was made up of pairs of high and low light images of the same scenes. There were no ""real"" labels.",,
RTE,10.48550/arXiv.1905.00537,4795,ACL,No,Textual Entaliment,Implicit Yes,No information,No information,Unknown,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No,"Collection of textual entailment tasks, chose not to go forward because it is more than 1 layer deep",,
glue,10.18653/v1/W18-5446,52167,ACL,Benchmark,Benchmark,,,,,,,,,,,,,,,,,,,,,,,,,,"No information given for NLI tasks (besides MNLI), so a third of the datasets are just collected like that with no specification",,
WNLI,,,ACL,No,Natural Language Inference,Yes for all,External,Multiple sources,Unknown,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,Questions easily disambiguated by a human,Yes,Multiple people,No information,No information,"Yes, external",Yes,Yes,Information is scattered an not the clear considering the low information GLUE gives about how they used this,https://cs.nyu.edu/~davise/papers/WinogradSchemas/WSCollection.html,
squadv2,10.48550/arXiv.1806.03822,70070,ACL,No,Reading Comprehension,Yes for some,OG,Daemo,Unknown,Money,No information,Formal instructions,No information (maybe to obtain clener data),No information,4.8,No information,"Yes, for some",Other,"If majority says answerable, keep shortest answer",No information,No information,Not applicable,151054 questions,Relevant and plausable answers,"Crowdworkers for questions, squadv1.1 for texts",No information,No information,No,"Yes, highlighting which questions are unanswerable","Yes, but broken",Link is easy to find but not included,,
MIT-Adobe FiveK,10.1109/CVPR.2011.5995332,2306,AAAI,No,Touching up images,Yes for all,OG,Students with claim of expertise,Unknown,Money,Unsure,No instructions,No information,5,5,5,"Yes, for all",Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Photographs of diverse scenes,No information,Photographs taken by a set of different photographers with SLR cameras,No information,No information,Not applicable,Not applicable,"Yes, but broken","Dataset was made up of images and their touched up versions. There were no ""real"" labels.",,
CLIP User Study,10.1609/aaai.v37i2.25353,222,AAAI,No,Evaluating the performance of CLIP-IQA on abstract perception,Yes for all,OG,No information,Unknown,No information,No information,Some Instructions,No information,No information,25,25,"Yes, for all",Quantitative,Average,No information,No information,No information,"More than 250,000 images",It is a large and diverse dataset,AVA dataset,15 image pairs,No information,"Yes, original",No information,No,,,
KonIQ-10k,10.1109/TIP.2020.2967829,222,AAAI,No,Image quality assessment,Yes for all,OG,Crowdflower - crowdworking platform,Project Specific,Money,No information,Formal instructions,Yes - eliminated some based on performance criteria,"1,459",No information,120,"Yes, for all",Quantitative,Average quality score,No information,Yes,ICC,99.2 million images,To achieve an authentic distortion of images,YFCC100m dataset,"The researchers used approximately 10 million images and then filtered/sampled them down to around 10 thousand, a number which they predetermined",No information,Yes - from external source,No information,Yes,Very good dataset documentation for most criteria. The paper contains two large sections extensively discussing the dataset.,Dataset link: http://database.mmsp-kn.de/,
sift flow,10.1109/TPAMI.2010.147,33167,TPAMI,No,Pixel level displacement field (mapping),Yes for all,OG,Annotators,Unknown,No information,No information,No instructions,No information,11,11,No information,"Yes, for all",Quantitative,Empirical probability curve.,Yes,Yes,Only standard deviation,"10 sparse, pre-selected points per image pair",No information,Author's personal video and image collection,No information,No information,No information,No information,No,"Almost no transparency, no raw data, nothing really",,
dark channel,10.1109/TPAMI.2010.168,6443,TPAMI,No,Remove haze from image.,Unsure,Unsure,Dark channel maps for images.,Not applicable,No information,No information,Some Instructions,Not applicable,1,1,No information,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Distribution of dark channel intensities,"5000 haze free images, resized so that max(width,height)=500","Capture statistics of dark channels across a variety of outdoor, haze free scenes; random draw after manual filtering to be representative.",Flickr.com and multiple search engines with 150 user-annotated tags; manual haze-free and daytime filtering.,No information,Large enough to robustly estimate the dark channel prior and its distribution.,No information,No information,No,"No data on image metadata, algorithmic dark-channel maps + ad-hoc sky masks.",,
imagenet-1k,10.48550/arXiv.1409.0575,38319,TPAMI,No,Image classification,Yes for all,OG,MTurk,Unknown,No information,Some training,Formal instructions,Scalability and global reach.,No information,"Pilot of >= 10, then no information",No information besides pilot,"Yes, for some",Quantitative,Majority (consensus) vote,Yes,No information,Not applicable,1000 object classes,Maximize diversity and coverage,General search engines,No information,"Use all retrievable images, then expand",No information,Unsure,Yes,"Quite good explanation of data collection and quality control, however bad transparency on annotator side.",,
NTU RGB+D,10.48550/arXiv.1604.02808,4080,AAAI,No,3D Human Activity Analysis,Yes for all,OG,Participants recorded with Kinetics v2 sensors,Unknown,No information,No information,Some Instructions,"Participants were of a variety of age, gender, and height",40,40,40,"Yes, for all",Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Physical human activities,No information,Human activities,No information,No information,Not applicable,Not applicable,"Yes, but broken","No labels really, items were 3D recordings of participants performing actions",,
swag,10.18653/v1/D18-1009,44198,ACL,No,Grounded commonsense inference,Yes for some,OG,MTurk,Unknown,Money,No information,Some Instructions,No,No information,1,1,No,Not applicable,Not applicable,Not applicable,Yes,ppa and Krippendorff’s α,20k youtube videos with 203 activity types and 128k movie captions,Mix in order to achieve broader coverage,"ActivityNet Captions and Large scale movie detection challenge, extra options generated",No information,No information,Yes,Yes,Yes,Quite a sofisticated way to generate a dataset,,
ace-2003,10.35111/7xtm-ys65,27202,ACL,No,Automatic content extraction,Yes for all,OG,Students and other,Generic Skill Based,No information,Some training,Formal instructions,Yes,No information,No information,2,"Yes, for all",Qualitative,No information,Yes,Yes,No information,"broadcast and newswire data in arabic, chinese and english",No information,News chanels (listed),No information,No information,Yes,Yes,No,"This paper is waay ahead of its time for ML annotations, psychology level of care taken for annotations",,
ECL / Electricity,10.24432/C58C86,6684,AAAI,No,Not specified. The dataset was made by observing electricity loads,Unknown,No information,No information,Unknown,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,Electricity consumption (no further specification is given),No information,No information,No information,No information,Yes,Very badly documented dataset. No official paper was made. Website provides little information about the dataset and uses bad grammar.,,
ETT,10.1609/aaai.v35i12.17325,6585,AAAI,No,Predicting Electricity Transformer Temperature,No / machine labelled,Not Labelled,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Oil temperature measures of the two electricity transformers,No information,Oil temperature of two electricity transformers from separate regions of the same Chinese province,No information,No information,Not applicable,Not applicable,Yes,,https://github.com/zhouhaoyi/ETDataset,
gigaword5,10.35111/wk4f-qt80,27202,ACL,No,No information,No / machine labelled,Not Labelled,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Newswire publications in english,No information,Multiple news agencies (listed),No information,No information,Not applicable,Not applicable,No,Barely any information available,,
US Weather,N/A,3426,AAAI,No,"To predict the ""wet-bulb"" feature based on other weather data",No / machine labelled,Not Labelled,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Weather data in the US,No information,"Weather data from 1,600 U.S. locations across 4 years in 1 hour periods",No information,No information,Not applicable,Not applicable,Yes,,Dataset description: https://www.ncei.noaa.gov/data/local-climatological-data/doc/LCD_documentation.pdf,
mc,https://doi.org/10.1080/01690969108406936,27202,ACL,No,Semantic similarity,Yes for all,OG,Students,Project Specific,No information,No information,Formal instructions,No information,34,34,34,"Yes, for all",Quantitative,Mean,No,No information,Not applicable,English words,No information,Rubenstein and Goodenough 1965,Yes,No information,Yes,Yes,Not applicable ,It's literally a list of 30 english words the author though to include,,
Cora,10.1609/aimag.v29i3.2157,4136,AAAI,No,Node classification in networked data,Unknown,No information,No information,Unknown,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,Cora portal for computer science research papers,No information,No information,No information,No information,No,Very minimal dataset description,,
CiteSeer,10.1609/aimag.v29i3.2157,2956,AAAI,No,Node classification in networked data,Unknown,No information,No information,Unknown,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,CiteSeer - autonomous citation indexing system,No information,No information,No information,No information,No,Very minimal dataset description,,
CelebAHQ,10.48550/arXiv.1710.10196,26341,CVPR,No,Higher-quality dataset of Celeba,No / machine labelled,External,Celeba dataset,Not applicable,Not applicable,Not applicable,Not applicable,No,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,High-resolution images of celebrity faces from CELEBA,To allow training GANs at megapixel resolutions and support research on high-quality generative models,Celeba dataset,30.000 - the high quality images,Chosen as a trade-off between image quality and variation,Not applicable,Not applicable,"Yes, but broken","Not so much information, since everything is based on Celeba dataset",,
FFHQ,10.48550/arXiv.1812.04948,20482,CVPR,No,High-quality dataset of human faces,No / machine labelled,Not Labelled,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,"70000 high-resolution human faces - more variation in terms of age, ethnicity, accessories and image background",To overcome limitations in diversity and quality of prior datasets for training high-fidelity GANs,Flickr,No information,Selected based on image quality and diversity using automated filtering and human verification,Not applicable,Not applicable,Yes,MTurk was used for filtering - but no compensations details are specified,,
BSDS300,10.1109/ICCV.2001.937655,17520,CVPR,No,Image segmentation evaluation and perceptual organization analysi,Yes for all,OG,Students,No prescreening (stated),No information,No information,Some Instructions,No information,10+25,At most 5 people,"""Something between 2 and 20 should be reasonable.""","Yes, for all",Quantitative,Independent segmentations + error metrics,No information,Yes,"GCC, LCE",300 representative 481x321 RGB images ,Images chosen for containing at least one discernible object to facilitate meaningful segmentation.,Corel image database,1000,No information,Segmentations represent non-overlapping regions; each pixel assigned to exactly one segment.,Defined to enable consistent measurement of segmentation accuracy and region-based statistics.,No,"no info about the 100 test dataset, or about the name of the dataset",,
ADE20K,10.1007/s11263-018-1140-0,19877,CVPR,No,Scene parsing and instance segmentation,Yes for all,OG,Single annotator using LabelMe,Generic Skill Based,No information,Not applicable,No instructions,"Expert annotator with open vocabulary, refined through iterative consistency and dictionary maintenance",1,1,Not applicable,No,Not applicable,Not applicable,No,Not applicable,Not applicable,20210 training images + 2000 validation images + 3000 testing images,No information,"LabelMe, SUN, Places",No information,Selected to cover the 900 scene categories defined in the SUN database,No fixed class list initially; vocabulary grew dynamically,A dictionary was maintained over time to reduce naming noise and improve consistency,Yes,Other annotators are used to check the accuracy in the end,,
iNaturalist,10.1109/CVPR.2018.00914,17756,CVPR,No,Species classification and detection,Yes for all,OG,Citizen science website iNaturalist,Generic Skill Based,No information,Not applicable,No instructions,No information,No information,No information,No information,"Yes, for all",Qualitative,Community reaches a consensus,Yes,Yes,Label verification rate; performance metrics reported include Top-1 and Top-5 accuracy,"Photographs of species in the wild from across the globe (859,000 images total)",Reflect real-world biodiversity distribution and long-tailed species frequencies,"iNaturalist.org (user-contributed photos, filtered for verified species IDs)",Yes – taxa selected based on ≥20 observations from ≥20 unique observers,Ensure each class had a reliable amount of diverse contributor data,Yes – taxonomic hierarchy (species-level labels within super-classes),Real-world biological taxonomy guided label structure,Yes,it also has a competition,https://www.gbif.org/dataset/50c9509d-22c7-4a22-a47d-8c48425ef4a7#description,
Conceptual Captions,N/A,2576,AAAI,No,Image captions,No / machine labelled,Not Labelled,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,5 bilion images from 1 billion internet webpages,No information,Internet webpages,No information,No information,Not applicable,Not applicable,Yes,It's unclear where they got the initial webpages from.,,
Places205,N/A,6819,CVPR,Benchmark,Scene classification,Yes for all,OG,MTurk,"Generic Skill Based, No prescreening (stated)",Money,Some training,Formal instructions,No information,No information,>=2,Initial round had default NO; YES required keypress. Second round had default YES.,"Yes, for some",Other,"YES/NO 2 times, then third round classifier + MTurk",No,No information,No information,Scene images across 205 categories,Designed to improve diversity and coverage beyond ImageNet and SUN.,"Google, Bing, and Flickr image search; expanded queries with 696 adjectives","minimum 5,000 per category, aiming for millions overall.",To support CNN training and maximize diversity; added more where needed via classifier bootstrapping.,SUN category ontology from WordNet guided scene definitions,"Defined categories to reflect spatial, functional, and linguistic distinctiveness of environments.",Yes,It's simply a subset of Places used as a benchmark,,
MUC-7,10.35111/jygm-3h55,27202,ACL,No,Named entity recognition and more,Yes for all,No information,No information,Unknown,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No,Barely any information about the dataset available,,
RG,10.1145/365628.365657,27202,ACL,No,Proving similarity of meaning is equal to similarity of context,Yes for all,OG,Students,Unknown,Money,No information,Formal instructions,No information,51,51,51,"Yes, for all",Quantitative,Average,No information,No information,No information,English words,No information,No information,No information,No information,Yes,Yes,Not applicable ,No information given about how the theme paris were generated,,
RW,N/A,27202,ACL,No,Word vector representation,Yes for all,OG,MTurk,"Previous platform, Location Qualification",Money,No information,Formal instructions,No information,No information,No information,10,"Yes, for all",Quantitative,Average after discarding outliers,No information,No information,No information,A rare word paired with a word similar in meaning,Yes,Generated,No information,No information,Yes,Yes,Yes,Could use more annotator information but gives good amount of info and item population has a good rationale and method of generation,,
Flickr30k,10.1162/tacl_a_00166,6375,AAAI,No,Image dentoations (image description connections),Yes for all,"Mix OG, External",Some crowdsourcing platform,Unknown,No information,No information,No information,No information,No information,5,5,"Yes, for all",Not applicable,Not applicable,No information,No information,No information,"""Photographs of everyday activities, events, and scenes""",No information,Flickr,No information,No information,Yes - external,No information,"Yes, but broken",,Flickr8K: https://www.ijcai.org/Proceedings/15/Papers/593.pdf,
SCWS,N/A,27202,ACL,No,Word vector representation,Yes for all,OG,MTurk,Previous platform,Money,No information,No information,Yes,No information,10,10,"Yes, for all",No information,No information,No information,No information,No information,Words paired with another similar word,"Yes, select diverse words",Generated,No information,No information,Yes,Yes,"Yes, but broken",,,
ws-353,10.1145/371920.372094,27202,ACL,Yes,Unknown,Yes for all,OG,No information,Unknown,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,Word pairs,No information,No information,No information,No information,No information,No information,No,Information gathered from secondary sources (Kaggle etc.) - paper doesn't mention anythin about dataset whatsoever and original website to download dataset it no longer up,,
Exchange-Rate,10.48550/arXiv.1703.07015,3151,AAAI,No,Daily exchange rates,Unknown,No information,No information,Unknown,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,Exchange rates of countries,No information,No information,No information,No information,No information,No information,No,Very limited description,,
ILI,N/A,3077,AAAI,No,Documenting the incidence of Influenza-like Ilness in the US,Implicit Yes,OG,Health care providers (medical professionals),Not applicable,Money,Some training,Formal instructions,Medical expertise is necessary,3200,1,1,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Patients with an influenza-like illness,To provide a dataset of the incidence of influenza-like illness,Outpatients visiting participating healthcare providers in the US,Not applicable,Not applicable,Yes,Provided through medical expertise,Yes,"Some columns do not apply very neatly. For example, the ones for sample size and item population are convoluted.",Dataset description found at: https://gis.cdc.gov/grasp/fluview/FluViewPhase2QuickReferenceGuide.pdf,
Jena Weather,N/A,3159,AAAI,No,"Documenting weather in Jena, Germany",No / machine labelled,OG,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Weather data,To provide a dataset of weather data,"Weather station in the Max Planc Institute in Jena, Germany",Not applicable,Not applicable,Not applicable,Not applicable,Yes,,,
word analogy task,10.48550/arXiv.1301.3781,52503,NeurIPS,No,Measuring synthactic and semantic regularities,No / machine labelled,Not Labelled,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Pairs of word pairs that has a similar relationship,Yes,Generated,No information,No information,Not applicable,Not applicable,Yes,,,
online object tracking,10.1109/CVPR.2013.312,5702,TPAMI,No,Evaluate object tracking algorithms.,Yes for all,OG,No information.,Unknown,No information,No information,No information,No information,No information,No information,Not applicable,No information,Not applicable,Not applicable,No information,No information,Not applicable.,"50 video sequences, each manually annotated with bounding boxes","Chosen for diversity in object motion and conditions, but not justified",Collected from existing tracking benchmarks and prior works.,No information,No information,Schema of 11 predefined attributes.,"Weak schema, the rationale is implied.","Yes, but broken",Major gaps in annotation transparency,,
LIVE In the Wild,10.1109/TIP.2015.2500021,222,AAAI,No,Image quality assessment,Yes for all,OG,MTurk,No prescreening (stated),Money,Some training,Formal instructions,No information,8100,Average of 175,No information,"Yes, for all",Quantitative,Average,No,Yes,SROCC,Naturally distorted images taken by unprofessional users on regular mobile devices,To provide a dataset of naturally distorted images,No information,No information,The researchers wanted to create a large dataset of naturally distorted images,Yes,No information,Yes,Generally good dataset description but lacks some important info such as item source,,
kth,10.1109/ICPR.2004.1334462,5577,TPAMI,No,Human action recognition from video.,Yes for all,OG,No information.,Unknown,No information,No information,No information,No information,No information,No information,No information,No information,Not applicable,Not applicable,No information,No information,Not applicable,2391 video sequences of 6 actions by 25 individuals in 4 scenarios.,No information,Recored by authors,No information,No information,Action categories defined in advance.,"Chosen actions are common, but no real mention of rationale.",No,Data is available only upon request. ,,
lip,10.48550/arXiv.1703.05446,3156,TPAMI,No,Segment human images into semantic parts.,Yes for all,OG,No information.,Unknown,No information,No information,No information,No information,No information,No information,No information,No information,Not applicable,Not applicable,No information,No information,Not applicable,COCO cropped human figures,"Implied- provide high variation in poses, backgrounds",COCO,No information,"50462 is considered beneficial, but not justified",19 predefined semantic part labels were used,"labels listed, no rationale for selection",Yes,"shit transparency, good paper",,
hmdb51,10.1109/ICCV.2011.6126543,6880,TPAMI,No,Human action recognition from video.,Yes for all,OG,Students.,Unknown,No information,No information,Some Instructions,No information,"""Group of students""",2,2,"Yes, for all",No information,No information,No information,No information,Not applicable.,"Human action video clips from movies, Youtube, archives.","Chosen for diversity, realism and to reflect everyday actions.","Digitized movies, Youtube, Google Videos, Prelinger archive.",60 initial categories reduced to 51 post filtering.,Theshold of 101 clips per category.,"Five types predefined: facial, body, interaction, etc.","Grouped based on similarity, but no detailed explanation.",Yes,"Somewhat decent, could've done a lot better.",,
citypersons,10.48550/arXiv.1702.05693,1100,TPAMI,No,Pedestrian detection,Yes for all,OG,Annotators,Unknown,No information,Some training,Some Instructions,No information,No information,1,1,No,Not applicable,Not applicable,No information,No information,Not applicable,5000 urban street images from Cityscapes,"Urban diversity (27 cities, 3 seasons)",Cityscapes,5000 images across train/val/test sets,Aligned with existing Cityscapes split.,"4 categories: pedestrian, rider, sitting, other. Pedestrians and riders get full-body bounding boxes.",Needed to train compatible detectors and to standardize occlusion handling.,Yes,Annotation protocol precise,,
SNLI,10.18653/v1/D15-1075,20243,ACL,No,Natural Language Inference,Yes for all,OG,MTurk,Unknown,Money,No information,Formal instructions,No information,~2500,No information,1,"Yes, for some",Quantitative,Majority vote,No information,Yes,No information,"image captions, supplied some sentence pairs ","Yes, images have literal descriptions",Flickr30k,No information,Be larger than other benchmarks,Yes,"Yes, force items to be balanced",No,"Generally good; Had validation round; Link not available in the paper, but very easy to find",,
dart,10.48550/arXiv.2007.02871,3592,ACL,No,Data to text,Yes for some,"Mix OG, External",MTurk,Unknown,Money,No information,Formal instructions,No information,No information,No information,No information,"Yes, for all",Qualitative,Experts look over the labels,No information,No information,No information,Tables,"Yes, tables are a major source of information",Wikipedia,No information,No information,Yes,Yes,Yes,"I only covered the annotated part of the data, there are two other parts that are either automatically annotated or come from other datasets",,
triviaQA,10.18653/v1/P17-1147,25657,ACL,No,Question answering,Yes for some,OG,"Web scraping for training, human annotator for dev/test set",Unknown,No information,No information,Formal instructions,No information,1,1*,6,"Yes, for all",Other,Each pair was given 6 labels to create 6 triples,Not applicable,Not applicable,Not applicable,question-answer pairs,Yes,14 different trivia websites (unspecified),No information,No information,"No, organically annotated (web scraping)",Controlling for bias,Yes,Had validation round; no information given about validator,,
SICK,N/A,11442,ACL,No,train compositional distributional semantic models,Yes for all,OG,MTurk,Unknown,Money,No information,Formal instructions,No information,No information,10,10,"Yes, for all",Quantitative,"Average, majority vote",No information,Yes,average of SD,English sentence pairs,"Yes, have a more CDSM related dataset",8k ImageFlickr and SemEval2012STS,No information,No information,Yes,"Yes, give examples to not have bias through rigid instructions",Yes,Well detailed data collection section,,
pets 2009,10.1109/PETS-WINTER.2009.5399556,3295,TPAMI,No,Crowd behavior analysis.,Yes for some,OG,Authors and students from the University of Reading,Unknown,No information,No information,Formal instructions,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,"People in public space, various crowd scenarios filed at the university campus","Yes, real-world relevance for surveillance scenarios (implicit)",Original films at University of Reading,Yes (planned scenarios),Increasing complexity,Yes,Task-specific definitions for crowd behavior events,Yes,"Nice read, tasks well specified",,
tb-100,10.1109/TPAMI.2014.2388226,3295,TPAMI,No,Single-object visual tracking,Yes for all,OG,Authors,Unknown,No information,No information,No information,No information,No information,1,1,No,Not applicable,Not applicable,No information,No information,No information,100 annotated video sequences of objects,"Yes, sequences selected to be diverse and representative",Publicly available datasets and online resources,Yes,Support robust evaluation and coverage of different challenges,Yes,Bounding box annotations with 11 defined visual tracking attributes. These represent key tracking challenges,Yes,"Formal instructions not specifically stated, but labelling appears to be systematic and consistent.",,
WebNLG 2017,10.18653/v1/W17-3518,2653,ACL,No,Natural Language Generation,Yes for all,External,No information,Unknown,No information,No information,No information,,,,,,,,,,,"Data text pairs, where data is RDF triples","Somewhat, doesn't mention why DBPedia",DBPedia,No information,No information,Yes,Yes,Yes,"The labels were extracted from DBPedia, but no information about how DBPedia labels are created",,
camvid,10.1016/j.patrec.2008.04.005,15656,TPAMI,No,Segmentation for driving scenarios.,Yes for all,OG,Recruited via Facebook ads,Project Specific,Money,Some training,Formal instructions,Ease of scaling annotation (not deeply explained),13 (from original 89 candidates),2 (label + verification),100% agreement required,"Yes, for all",Other,Manual inspection and correction,Yes,No information,No information,701 pixel-labeled frames from 4 driving video sequences,"Yes, driving perspective with various traffic scenarios",Custom filmed.,"Yes, 701 labeled frames","Based on driving coverage, variety of classes and events.","Yes, 32 semantic classes",Derived from relevant driving scene elements,Yes,HOLY SHIT good paper,,
ucf101,10.48550/arXiv.1212.0402,13639,TPAMI,No,Action recognition,Yes for all,OG,Authors,Unknown,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,13320 video clips from 101 action categories from Youtube,Increase diversity and reflect real-world conditions,Youtube,"Yes, 25 groups per class",Maximize variance,101 specific human action categories,Increase diversity,Yes,"Not bad, no annotator information",,
ccnet,10.48550/arXiv.1911.00359,2660,ACL,No,Pretraining,No / machine labelled,Not Labelled,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Common crawl snapshots filtered for high quality,"Yes, goes into detail",Common Crawl,No information,Be as large as possible,Not applicable,Not applicable,Yes,"Somewhat of a dataset, more like a way to generate a dataset",,
Places365,10.48550/arXiv.1909.02410,7308,CVPR,No,Scene classification,Yes for all,OG,MTurk,"Generic Skill Based, No prescreening (stated)",Money,Some training,Formal instructions,No information,No information,>=2,Initial round had default NO; YES required keypress. Second round had default YES.,"Yes, for some",Other,"YES/NO 2 times, then third round classifier + MTurk",No,No information,No information,Scene photographs labeled with 365+ semantic categories,"Aimed to exhaustively cover “places a human can be in,” using functional and perceptual criteria.","Google, Bing, and Flickr image search; expanded queries with 696 adjectives","minimum 5,000 per category, aiming for millions overall.",To support CNN training and maximize diversity; added more where needed via classifier bootstrapping.,SUN category ontology from WordNet guided scene definitions,"Defined categories to reflect spatial, functional, and linguistic distinctiveness of environments.",Yes,it has two versions that will be mentioned bellow,,
Places365-Standard,10.1109/TPAMI.2017.2723009,3942,CVPR,No,Scene classification,Yes for all,OG,MTurk,"Generic Skill Based, No prescreening (stated)",Money,Some training,Formal instructions,No information,No information,>=2,Initial round had default NO; YES required keypress. Second round had default YES.,"Yes, for some",Other,"YES/NO 2 times, then third round classifier + MTurk",No,No information,No information,Scene photographs labeled with 365+ semantic categories,"Aimed to exhaustively cover “places a human can be in,” using functional and perceptual criteria.","Google, Bing, and Flickr image search; expanded queries with 696 adjectives","minimum 5,000 per category, aiming for millions overall.",To support CNN training and maximize diversity; added more where needed via classifier bootstrapping.,SUN category ontology from WordNet guided scene definitions,"Defined categories to reflect spatial, functional, and linguistic distinctiveness of environments.",Yes,"less training and pre-class training images, academic/research use, public",,
Places365-Challange,10.1109/TPAMI.2017.2723009,0,CVPR,No,Scene classification,Yes for all,OG,MTurk,"Generic Skill Based, No prescreening (stated)",Money,Some training,Formal instructions,No information,No information,>=2,Initial round had default NO; YES required keypress. Second round had default YES.,"Yes, for some",Other,"YES/NO 2 times, then third round classifier + MTurk",No,No information,No information,Scene photographs labeled with 365+ semantic categories,"Aimed to exhaustively cover “places a human can be in,” using functional and perceptual criteria.","Google, Bing, and Flickr image search; expanded queries with 696 adjectives","minimum 5,000 per category, aiming for millions overall.",To support CNN training and maximize diversity; added more where needed via classifier bootstrapping.,SUN category ontology from WordNet guided scene definitions,"Defined categories to reflect spatial, functional, and linguistic distinctiveness of environments.",Yes,"significantly more images, used for large scale training/competition, challange-specific but available ",,
LSUN,10.48550/arXiv.1506.03365,33443,CVPR,No,Scene classification and object classification,Yes for some,OG,MTurk,Project Specific,Money,Some training,Formal instructions,"The ability to obtain many labels, quickly and at minimal cost",No information,2,No information,"Yes, for all",Other,Two annotators must agree; automated classifier confirms or extends labels.,No,Yes,Precision estimates from expert relabeling,Internet images from Google,"Sought high-density image coverage per category (e.g., ~1M per category).","Google, queries with appropriate adjectives and synonyms",~1 million images per scene/object category.,To provide denser coverage than ImageNet or Places for deep model training.,Binary classification (positive/negative) per category.,Simplicity allowed scalable semi-automatic pipeline and high consistency.,No,,,
1B word,10.48550/arXiv.1312.3005,27365,ACL,No,statistical machine translation,No / machine labelled,Not Labelled,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,english text data from news,No information,WMT11,Yes,Strike a balance between size and relevancy,Not applicable,Not applicable,Yes,"Dataset usually used for pretraining or something, can be used to evaluate how good models are at predicting the next word",,
Set14,10.1007/978-3-642-27413-8_47,13342,CVPR,Benchmark,Single image super-resolution (scale-up),No / machine labelled,Not Labelled,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,14 images in differnet resolutions,A set used for testing ,Public images and captured screenshots,No information,No information,Not applicable,Not applicable,No,"It is a set of images in different resolutions, no labels needed",https://figshare.com/articles/dataset/BSD100_Set5_Set14_Urban100/21586188?file=38256855,
Set5,10.5244/C.26.135,13342,CVPR,Benchmark,Single image super-resolution (SR) evaluation,No / machine labelled,OG,Original clean high-resolution images,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,"5 standard photographic images: baby, bird, butterfly, head, woman",A set used for testing ,Public images archives,Fixed at 5,Compact benchmark,Not applicable,Not applicable,No,,https://figshare.com/articles/dataset/BSD100_Set5_Set14_Urban100/21586188?file=38256852,
Waymo,10.1109/CVPR42600.2020.00252,4375,CVPR,No,2D/3D object detection and tracking,Yes for all,OG,Annotators using production-level labeling tools,Project Specific,No information,No information,No information,Highly experienced annotators using internal production tools.,No information,No information,Exhaustivly,No information,No information,No information,No information,No information,No information,"Images representing different scenes from suburban and urban areas, different times o",Aimed for high geographic and temporal diversity to study domain shifts.,Images collected with LiDAR sensors and high-resolution pinhole camera,No information,No information,"Defined label format: 7-DOF 3D bounding boxes, 4-DOF 2D bounding boxes, tracking IDs.","Supports multimodal tracking and detection tasks, including level-of-difficulty categorization.",Yes,,,
SVHN,N/A,26797,CVPR,No,House-number signs detection,Yes for some,OG,MTurk,Unknown,Money,No information,No information,No information,No inforamtion,No information,No information,No information,No information,No information,No information,Yes,Human-level accuracy ≈98%	,Digits from house number signs in Street View,Demonstrate the difficulty of recognizing these digits when the problem is approached with hand-designed features,Google Street View Images,No information,No information,Digit label (0–9) and optional bounding box for Full Numbers.,Designed to support both classification and end-to-end OCR tasks.,Yes,,,
StanfordCars,10.1109/ICCVW.2013.77,8485,CVPR,No,"Fine-grained object categorization (e.g., car make/model), 3D object reconstruction, pose estimation",Yes for all,External,MTurk,Generic Skill Based,Money,Some training,Formal instructions,Crowd workers were filtered and guided to ensure fine-grained discrimination accuracy.,No information,3,All elements are covered,"Yes, for all",Other,Confidence-weighted majority,No,Yes,"Classifier performance (accuracy), visual verification",Images representing different cars,Cars that have visual appearence differencies,"Flickr, Google, Bing",No information,No information,Bounding boxes used for cropping; class names used for fine-grained categorization.,Dataset was planned for release with paper publication.,No,,,
Objects365,10.1109/ICCV.2019.00852,1422,CVPR,No,Object detection,Yes for all,OG,"Annotators, inspectors and examiners",Generic Skill Based,Money,Some training,Formal instructions,No information,No information,3 + 2 checks,at least 1,"Yes, for all",Qualitative,Inspector and examiner consensus,No,No information,No information,"Non-iconic, diverse, natural photographs",Varied categories,Flickr,No information,"Dataset designed to exceed COCO and VOC in scale, density, and category breadth.",365 object categories organized by 11 super-categories; full annotations with bounding boxes.,Structured for large-scale detection tasks; built on super-category specialization and reviewed tagging.,Yes,,,
DreamBooth,10.1109/CVPR52729.2023.02155,1565,CVPR,No,Subject-driven image generation,No / machine labelled,OG,Manual image grouping by authors,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,"Pets, objects, cartoons, and more",Chosen to cover both animate and inanimate classes and varied complexity.,Unsplash and author collections,Each subject has ~3–5 images for training; test prompts total 25 for each subject.,Few-shot design supports testing generalization from minimal input data.,Not applicable,Not applicable,Yes,,,
ImageNet-R,10.1109/ICCV48922.2021.00823,1321,CVPR,No,Object classification under style-based distribution shift,Yes for all,OG,Mturk and students,Unknown,Money,No information,No information,No information,No information,2,1,"Yes, for all",Qualitative,Second round of checking,No information,No information,No information,Images containing various renditions,Designed to test robustness to textural and stylistic variation,Flickradn web search,30000,Balanced across a subset of 200 ImageNet classes with sufficient artistic variety.,,Schema ensures renditions are recognizable depictions of target classes.,Yes,,,
tacred,10.18653/v1/D17-1004,2221,ACL,No,TAC Relation Extraction,Yes for all,OG,MTurk,Unknown,Money,No information,Formal instructions,No information,No information,No information,1,"Yes, for some",No information,No information,No information,Yes,Fleiss Kappa,Queries from previous contests,No information,TAC KPB 2009-2015,No information,Larger than previous datasets,No information,No information,No,"Nice data statistics, could have used more annotators descriptions and menioning whether schema was used Data is present on the LDC website because of copyright",,
ag's news,10.48550/arXiv.1509.01626,5675,ACL,No,Classification with Character-level Convolutional Network training,No / machine labelled,Not Labelled,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,"News articles from 4 different ""classes""",No information,2000 news sources,No information,No information,Not applicable,Not applicable,Yes,"Literally just a paragraph, i don't even undestand how you would use this",,
Traffic,N/A,3250,AAAI,No,Traffic data prediction,No / machine labelled,Not Labelled,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Traffic data in San Francisco Bay Area,No information,PeMS,"Yes, 862 sensors from January 2015 to December 2016",No information,Not applicable,Not applicable,Yes,,,
wmt16,10.18653/v1/W16-2301,23797,ACL,No,Machine Translation,Yes for all,"Mix OG, External",Professional Translators/,Generic Skill Based,Money,No information,Formal instructions,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,Sentences from news articles (testing) and mixed sources (training),No information,Multiple sources (listed),No information,No information,No information,No information,Yes,"Looked only at news corpus, cause that is what people usually use. Training set is a mix of stuff ranging from common crawl to europarl. ""Professional annotators"" is only what we get in terms of annotators, procedure is not really described. ",,
ImageNet-A,10.48550/arXiv.1907.07174,2710,CVPR,No,Image classification,Yes for all,OG,Graduate students,Generic Skill Based,No information,No information,Formal instructions,A large share of images contain multiple classes per image,No information,No information,1,"Yes, for all",Qualitative,Manual verification,No information,No information,No information,Naturally occurring hard examples,Images chosen to test generalization beyond texture-based cues and spurious correlations.,"iNaturalist, Flickr, DuckDuckGo","Targeted 7,500 images across 200 ImageNet classes.",Sample size allows evaluation of robustness while maintaining diversity.,"Based on existing ImageNet class definitions, with a restricted, curated subset.",Selected 200 classes where classification errors would be visually and semantically obvious.,Yes,,,
ImageNet-Sketch,10.48550/arXiv.1905.13549,1016,CVPR,No,Image classification for sketch-like images,Yes for all,External,ImageNet-1K,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,No,Not applicable,Not applicable,No,No information,No information,"Sketch-style images representing 1,000 ImageNet classes",For evaluating the out-of-domain classification performance of vision models trained on ImageNet ,"Google Images queries ""sketch of...""",50000 images,50 images for each of the 1000 ImageNet classes,"Each image assigned to one of the 1,000 standard ImageNet classes.",Labels map directly to known ImageNet classes to support domain shift evaluation.,Yes,,,
ImageNet-V2,10.48550/arXiv.1902.10811,1318,CVPR,No,Image classification,Yes for all,OG,MTurk,Generic Skill Based,Money,Some training,Formal instructions,Following the steps from ImageNet ,No information,At least 10,Certain threshold for each metric,"Yes, for some",Other,"Nearest neighbor, and manual verification",No information,No information,No information,Images from Flickr (post-ImageNet time frame),Mimics original ImageNet validation set distribution for replication purposes.,Flickr,"10,000 images selected, 10 per class across 1,000 classes.",Would result in accuracy scores with small confidence intervals,Matched ImageNet class definitions; MTurk task aligned with original UI.,Schema ensured consistent human-recognizable class semantics.,Yes,"It mentions an interesting bias: take into consideration that these datasets have built long time ago, classes like ""car"" and ""phone"" have changed significantly ",,
CC12M,10.48550/arXiv.2102.08981,2162,CVPR,No,Visual-and-language tasks,No / machine labelled,OG,"Web alt-text, processed by automated filters",Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,12.4M image-text pairs,Designed to improve generalization and long-tail coverage beyond CC3M.,Web,No information,No information,No information,No information,Yes,,,
InstructPix2Pix,10.1109/CVPR52729.2023.01764,704,CVPR,No,Instruction-based image editing,No / machine labelled,Not Labelled,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,LAION-Aesthetics 6.5+ image captions and their synthetic variants,"LAION-Aesthetics chosen for diversity and relevance; edits target variety in structure, style, context.","LAION-Aesthetics (for captions), Stable Diffusion + Prompt-to-Prompt (for images)",No information,No information,"Instruction-based triplets: (input image, edit instruction, edited image).",Designed to support learning of image edits from precise natural language instructions.,Yes,,,
conll-2002,N/A,7730,ACL,No,named entity recognition,Yes for all,OG,Agency/Project,Unknown,Money,No information,Formal instructions,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,belgian and spanish newswire/newspapers,No information,News agency/unknown,No information,No information,"Yes, external",No information,"Yes, but broken","Paper has both spanish and dutch, they both compete in how few information they can give about annotators (one paragraph per langauge)",,
LAION-Aesthetic,https://github.com/LAION-AI/laion-datasets/blob/main/laion-aesthetic.md,822,CVPR,No,Image generation,No / machine labelled,External,Alt-text from web images + aesthetic scores predicted by model,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,High-quality aesthetic web images with meaningful alt-text,To improve the quality of training data for generative vision-language models,Web crawl via Common Crawl,No information,No information,Not applicable,Not applicable,Yes,,,
kitti,10.1109/CVPR.2012.6248074,15609,TPAMI,Benchmark,3D object detection,Yes for some,OG,Authors and hired annotators for 3D boxes,Unknown,No information,No information,Formal instructions,No information,No information,No information,No information,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,"389 image pairs for stereo flow, 22 stereo sequences for vo/slam, 200 k object annotations for 3D detection","Capture realistic, non synthetic driving environments","Station wagon equipped with  dual stereo camera in Karlsruhe, Germany",K means (k = 400) selected 389 image pairs,Maximize diversity via clustering and ensure representative odometry lengths and loop closures.,Following PASCAL-VOC labels,No information,Yes,"No redundant labelling, very technical imo",,
Oxford-IIIT Pets,10.1109/CVPR.2012.6248092,11763,CVPR,No,Cats and dogs classification,Yes for all,OG,Annotators,Unknown,No information,No information,No information,No information,No information,No information,1,No information,No information,No information,No information,No information,No information,Images of cats and dogs of different breed,The visual problem is very chalanging as these animals are very deformable and they can be quite subtle differences between the breeds,"Caster, Dogster, Flickr and Google images",about 200 per breed,No information,"Breed label, head bounding box, segmentation (trimap: foreground, background, ambiguous).",Designed to support multi-task evaluation: classification and segmentation.,"Yes, but broken",,,
lama,10.18653/v1/D19-1250,1816,ACL,No,Test factual and common sense knowledge,Yes for some,"Mix OG, External",External,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,1,"Yes, for some",Other,Random choice,Not applicable,Not applicable,Not applicable,Sentences with a gap,Choose different QA/CS sources for variety,Multiple other datasets (listed),No information,No information,Not applicable,Not applicable,Yes,This is an aggregate of multiple datsets modified to fit the pattern they want to go for,,
foot keypoint,10.1109/TPAMI.2019.2929257,2666,TPAMI,No,2D foot keypoint annotations,Yes for all,OG,Clickworker crowdworkers,Unknown,No information,No information,Some Instructions,No information,No information,1,No information,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,"15000 foot instances, 14000 from COCO + 545 from coco validation","Fill the gap in existing datasets, which only annotate ankles",Subset of images from COCO,No information,Large and diverse sample of foot instances,"6 foot keypoints (big toe, small toe, heel for each foot)",Accurate foot pose estimation and avoid some techniques,Yes,"Single pass annotations, formal instructions just said accurate anatomical placement, extends COCO",,
DTD,10.1109/CVPR.2014.461,7865,CVPR,Benchmark,Texture attribute recognition and material classification,Yes for all,OG,MTurk + authors,Unknown,Money,No information,Formal instructions,No information,No information,3 + authors,1,"Yes, for all",Qualitative,Authors did manual verification,No information,No information,No information,Real-world texture images,Designed for semantic coverage and variability in real-world conditions.,"Google Images, Flickr",At least 120 representative images for each attribute ,No information,"47 English adjectives describing textures (e.g., wrinkled, striped, bubbly).",Based on psycholinguistic studies and refined for visual relevance.,Yes,,,
mpii,10.1109/CVPR.2014.471,2666,TPAMI,No,2D human pose estimation,Yes for all,OG,In-house + MTurk,Project Specific,Money,Some training,Some Instructions,Chose MTurk based on performance in qualification task,No information,1,No information,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,40522 annotated people from 24920 frames from 3913 YT videos,"Cover variety of real-world poses, 823 activities in 21 categories",Manually sampled (5s interval) from YT videos,10 videos per activity,Ensure diversity,"14 body joint keypoints, 3D head & torso orientation",No information,Yes,"Single pass, data diversity from systematic activity-guided selection",,
tfd,N/A,48297,NeurIPS,Yes,,,,,,,,,,,,,,,,,,,,,,,,,,No,"""Toronto Face Dataset"", DS paper and DS technically exist but not found on the Internet",,
wmt14,10.3115/v1/W14-3302,136484,NeurIPS,No,Machine translation task,Yes for all,"Mix OG, External",Professional translators,Project Specific,Money,No information,Formal instructions,No information,No information,No information,No information,"Yes, for some",Quantitative,No information,No,No,Not applicable,Sentences from news articles and other sources,"General, broadly applicable",Multiple sources,No information,No information,No information,No information,Yes,,,
google news,N/A,25301,NeurIPS,Yes,,,,,,,,,,,,,,,,,,,,,,,,,,,"Internal, no information",,
roadscene,10.48550/arXiv.2401.07322,1233,TPAMI,No,Roadscene for autonomous driving,Yes for some,OG,Students and professionals + semi-auto annotation,Unknown,No information,No information,Formal instructions,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,Images from Bangladesh street with in-card dashboard recording,Diverse real-world scenarios in Bangladesh,Original video footage,"20334: 18762 train, 1004 validate, 649 test (3985 manually labelled in train)",Ensure diverse geographic and environmental conditions,13 object categories,Support training and evaluation for raoad scene understanding tasks,Yes,"Objects must be 50% more visible to annotate, boxes tight, overlap acceptable in cluttered scenes, semi automated labelling with YOLOv6, followed by human correction]",,
strategyQA,10.1162/tacl_a_00370,6574,ACL,No,Question answering,Yes for all,OG,MTurk,"Location Qualification, Previous platform",Money,Some training,Formal instructions,Many labellers to create diverse questions,19 and 54,1 and 3,1 and 3,"Yes, for all",No information,No information,No information,Yes,Cohen's kappa,implicit questions that require an answering strategy,"Yes, very strong ",Generated by workers,No information,No information,Yes,"Yes, give soft guidance to workers","Yes, but broken","Excellent paper overall, interesting item selection, has good validation round, overall a refreshing paper",,
self-instruct,10.18653/v1/2023.acl-long.754,896,ACL,No,Instruction-tune a LLM,No / machine labelled,OG,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Input/instruction pairs generated from some example pairs,"Yes, section 2.1",Authors and labmates,No information,No information,Not applicable,Not applicable,Not applicable ,,,
widerface,10.1109/CVPR.2016.596,2730,TPAMI,No,Face detection,Yes for all,OG,Annotators,Unknown,No information,No information,Formal instructions,No information,No information,"1, but cross checked by 2 others",1,"Yes, for all",Qualitative,Cross-checking,No information,No information,No information,Images of 60 event categories,Maximize variation in scene and face characteristics,"WIDER dataset subset, images from Bing and Google search","32203 images, 393703 faces",Exceeds prior datasets 10x and capture variability,Yes,"Capture variability in pose, occlusion and event context",Yes,,,
PubMed,10.1609/aimag.v29i3.2157,4136,AAAI,Yes,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CUHK03,10.1109/CVPR.2014.27,2311,AAAI,No,Person re-identification,Yes for some,OG,No information,Unknown,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,Images of pedestrians,No information,No information,No information,No information,Yes,No information,Yes,,Data link: http://www.ee.cuhk.edu.hk/~xgwang/CUHK_identification.html,
got-10k,10.1109/TPAMI.2019.2957464,1915,TPAMI,No,Object detection,Yes for all,OG,Professional annotators,Project Specific,Money,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,Over 10000 video segments featuring 563 classes and 87 motion classes,Comprehensive and unbiased coverage of diverse moving objects,Youtube,"Yes, large scale benchmark",Unified training and stable evaluation of deep trackers,Object and motion classes were defined using the semantic hierarchy of WordNet,Comprehensive and relatively unbiased coverage of diverse moving objects,Yes,,,
superni,10.18653/v1/2022.emnlp-main.340,1071,ACL,No,Measure how well LMs can generalize on tasks,Yes for all,OG,Volunteers over github annotating their dataset type,Unknown,Volunteer,No information,Formal instructions,No information,88,1,1,"Yes, for some",Qualitative,Expert annotator modified it,No information,Not applicable,Not applicable,Datasets collected by the volunteers,Create a variety of tasks,Mix of sources,Yes,"6,5k each task to avoid imbalances",Yes,Making sure instructions were sufficient,Yes,The task itself here was submitting datasets labelled by NLP task. Had reviewing and quality control. A concern here would be whether the source of the dataset was given so that infringement is avoided. ,,
DukeMTMC-reID,10.48550/arXiv.1609.01775,2412,AAAI,No,"Multi-Target, Multi-Camera Tracking",Yes for all,OG,No information,Unknown,No information,No information,No information,No information,5,No information,No information,No information,No information,No information,No information,No information,No information,Videos of pedestrians on the Duke University Campus,No information,8 outdoor cameras,"Yes, videos taken during breaks between lessons",Because traffic is heavy,Yes,No information,"Yes, but broken",,,
BSD68,10.1109/ICCV.2001.937655,1931,CVPR,No,Image segmentation evaluation and perceptual organization analysi,Yes for all,OG,Students,No prescreening (stated),No information,No information,Some Instructions,No information,10+25,At most 5 people,"""Something between 2 and 20 should be reasonable.""","Yes, for all",Quantitative,Independent segmentations + error metrics,No information,Yes,"GCC, LCE",68 images,No information,Corel image database,1000,No information,Segmentations represent non-overlapping regions; each pixel assigned to exactly one segment.,Defined to enable consistent measurement of segmentation accuracy and region-based statistics.,No,"It is a subset of BSD300, and should be introduced by the same paper, but it's not mentioned anywhere in the paper",https://www.kaggle.com/code/mpwolke/berkeley-segmentation-dataset-68/notebook,
svamp,10.18653/v1/2021.naacl-main.168,6392,ACL,No,Math problems solver,Yes for all,OG,"Authors, Collegues",Unknown,No information,No information,Formal instructions,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,Math problems up to grade 4 with simple variations,"Previous datasets made models rely on shallow heuristics, so variation needed",ASDiv-A,No information,No information,Yes,Define variations for the problems,Yes,"Not clear what the compensation was here, and not clear how the tasks were distributed",,
Fashion-MNIST,10.48550/arXiv.1708.07747,2311,AAAI,No,To build a better MNIST,Yes for all,OG,Unsure,Unknown,No information,No information,No information,No information,Unsure,No information,No information,No information,No information,No information,No information,No information,No information,Images of clothing,To have something more complex than written numbers,Zalando's website,"Yes, 70,000",No information,"Yes, original",To mimic the size of MNISTs schema,Yes,,,
Market-1501,10.1109/ICCV.2015.133,2412,AAAI,No,Person re-identification,Yes for all,OG,No information,Unknown,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,Pedestrian images,No information,6 cameras in front of a campus supermarket,No information,No information,Yes,No information,"Yes, but broken",,,
NQ,10.1162/tacl_a_00276,25764,ACL,No,Question answering,Yes for all,OG,Annotators,Unknown,No information,No information,Formal instructions,No information,~50,1*,1,"Yes, for some",Other,Post-hoc by experts and in some complicated quantitative way,No information,Yes,Constructed formula,Questions posed by users in a short amount of time,Yes,Google,No information,No information,Yes,Yes,Yes,Had validation round; no information about how they recruted annotators/presreening etc.,,
NaturalQuestions-Open,10.18653/v1/P19-1612,234,ACL,No,Question answering with unanswerable questions,Yes for all,External,Annotators,Unknown,No information,No information,Formal instructions,No information,~50,1*,1,"Yes, for some",Other,Post-hoc by experts and in some complicated quantitative way,No information,No information,Constructed formula,Questions with short answers ,"Yes, keep cannonical answers",NQ dataset,No information,No information,Yes,Not applicable,No,This is just a modified version of the previous dataset,,
news summarization,10.48550/arXiv.2301.13848,233,ACL,No,Summarization,Yes for all,OG,Upwork,Project Specific,Money,No information,Formal instructions,No information,6,3,3,"Yes, for all",No information,No information,No information,No information,No information,News articles,"Yes, the llms were previously evaluated on those datasets",CNN/DM and XSUM,"Yes, 100",No information,Yes,"Yes, to have better task grounding",Yes,,,
PEMSD4,10.1609/aaai.v33i01.3301922,2246,AAAI,No,Traffic prediction,No / machine labelled,Not Labelled,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Traffic in San Francisco Bay Area,No information,PeMS,"Yes, 3848 detectors from January to February in 2018",No information,Not applicable,Not applicable,No,,,
PEMSD8,10.1609/aaai.v33i01.3301922,2246,AAAI,No,Traffic prediction,No / machine labelled,Not Labelled,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Traffic in San Bernardino,No information,PeMS,"Yes, 1979 detectors from July to August in 2016",No information,Not applicable,Not applicable,No,,,
Countries,N/A,2228,AAAI,No,General info about countries,No / machine labelled,Not Labelled,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Countries in the world as defined by ISO 3166-1,No information,"Mainly Wikipedia, but other sources are included","Yes, all countries",Authors of the dataset wanted to make a list of all countries,Not applicable,Not applicable,Yes,,GitHub link: https://github.com/mledoze/countries,
DUT-OMRON,10.1109/CVPR.2013.407,1013,AAAI,No,Visual saliency detection,Yes for all,OG,No information,Unknown,No information,No information,Some Instructions,No information,25,5,5,"Yes, for all",Quantitative,Average of the bounding boxes,No information,No information,No information,Unsure,No information,SUN dataset,"Yes, 10,000 and then reduced it to 5,172",No information,Yes,No information,"Yes, but broken","Since the dataset link was broken, most of the info was found online at a different website and paper","Dataset link: https://saliencydetection.net/dut-omron/, Additional paper link: https://saliencydetection.net/dut-omron/download/FCV2014.pdf",
DUTS,10.1109/CVPR.2017.404,1141,AAAI,No,Visual saliency detection,Yes for all,OG,No information,Unknown,No information,No information,No information,No information,50,No information,No information,No information,No information,No information,No information,No information,No information,Unsure,No information,ImageNet DET and SUN datasets,No information,No information,Yes,No information,Yes,,,
qags,10.18653/v1/2020.acl-main.450,233,ACL,No,Automatic evaluation metrics for summarization,Yes for all,OG,MTurk,"Location Qualification, Previous platform",Money,No information,Formal instructions,No information,No information,3,3,"Yes, for all",Quantitative,Majority vote,No information,Yes,Kripendorff's alpha,News articles paired with a summary,To compare with prior work,CNN/DM and XSUM,No information,No information,No information,No information,Yes,,,
ECSSD,10.1109/TPAMI.2015.2465960,1013,AAAI,No,Visual saliency detection,Yes for all,"Mix OG, External","Other, with no claim of expertise",Unknown,Unsure,No information,Some Instructions,No information,5,5,5,"Yes, for all",Quantitative,Average of the binary masks,No information,Yes,F1 score,Images of various objects and scenes,To provide natural images for visual saliency detection,The Internet,Yes,No information,Yes,No information,No,,,
summeval,10.1162/tacl_a_00373,233,ACL,No,assemble the largest collection of summaries generated by models trained on the CNN/DailyMail news dataset,Yes for all,OG,"MTurk, Experts","Previous platform, Location Qualification",Money,No information,Formal instructions,Ensure native speakers (mturk) and have more wisdom (experts),"No information (mturk), 3 (experts)",8,8,"Yes, for all",Qualitative,Discussion,Yes,Yes,Krippendorff’s alpha,News articles,standard dataset for training summarization models,CNN/DM,"Yes, 100",No information,Yes,Yes,Yes,"Validations seems like it was quite strong, but otherwise mid cause they didn't annotate many things manually, just collected them",,
topical-chat,10.48550/arXiv.2308.11995,233,ACL,No,Conversational bots,Yes for all,OG,MTurk,Previous platform,Money,No information,Formal instructions,Experienced turkers,No information,1,1,No information,No information,No information,No information,No information,No information,"Messages within a conversation, and the conversation itself","Yes, both people had different knowledge to simulate real world scenarios",MTurk,No information,No information,No information,No information,Yes,There were many reading sets to prepare annoators for the conversations. I said no for annotation schema since there were only instructions). Had some validation described,,
entityquestions,10.18653/v1/2021.emnlp-main.496,197,ACL,No,Open-domain question answering,No / machine labelled,External,Wikipedia,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,natural language questions converted from relation triples,"Yes, use TRex dataset to verify relation is easily answerable",Wikipedia,No information,No information,Not applicable,Not applicable,Yes,No validation or anything but at least had good entity selection criteria,,
bigearthnet-s2,10.1109/IGARSS.2019.8900532,353,TPAMI,No,Land classification,No / machine labelled,External,CORINE Land Cover,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,No information,No,No information,No information,No information,No information,No information,590326 Sentinel-2 image patches from 125 tiles across 10 EU countries,Wide geographic coverage and low cloud cover.,Satellite images,Yes,Create a large scale archive,"Yes, from external",CLC2018 standard system for EU,Yes,,,
fmow-s2,10.48550/arXiv.1711.07846,353,TPAMI,No,Land use and building function classification from satellite,Yes for all,OG,Crowdsourcing via DigitalGlobe GeoHIVE crowd workesrs,Project Specific,No information,No information,Formal instructions,"Yes, trusted users from universities, industry and prior works",642 and around 2800 hours of work,No information,No information,No information,No information,No information,No information,No information,No information,"Satellite image bounding boxes from >1 million images, 63 categories, global coverage",Geographic and functional diversity,DigitalGlobe ,Yes,Targeted 1 million images across 50-100 categories,Yes,Based on OpenStreetMap and NATO dictionaries,Yes,"3 phase annotation: location selection, image selection and bounding box creation",,
MultiArith,10.18653/v1/D15-1202,1766,ACL,No,Arithmetic problem solving from natural language,No / machine labelled,Not Labelled,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Multi-step arithmetic problems,Test a system's ability to handle multi-step problems,www.commoncoresheets.com,600,All the problems available on the website,"Gold expressions constructed for each problem, using monotonic expression trees.",Reflects target solution logic with read-once constraints.,No,,,
tiny imagenet,N/A,1211,TPAMI,Yes,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
cub-200-2011 birds,N/A,24129,TPAMI,No,Bird species classification,Yes for all,OG,MTurk,Unknown,No information,No information,Formal instructions,No information,5 different workers for differnet parts,5,5,"Yes, for all",Quantitative,Median of annotations,No,No information,No information,11788 images from 200 bird species,Research in fine-grained recognition,Flickr,Yes,Double the original CUB-200 size,Yes,Based on domain specific bird features,Yes,,,
fgvc aircraft,10.48550/arXiv.1306.5151,7885,TPAMI,No,Airplane model classification,Yes for all,"Mix OG, External",Aircraft spotters + MTurk,Unknown,Money,No information,Formal instructions,No information,10 aircraft spotters + mturk annotators,3,2,"Yes, for all",Quantitative,Averaged bounding boxes from valid overlapping annotations,No information,No information,No information,10k airplane images,"diversity, even distribution across variants",airliners.net,yes,100 images per variant to create balanced and fine grained benchmark,No information,No information,Yes,"Each image annotated by 2-3 MTurk workers, bounding boxes kept if >= 2 workers agreed. Labels (variant/family/manufacturer) came from Airliners.net",,
PopQA,10.18653/v1/2023.acl-long.546,197,ACL,Benchmark,"Open-domain question answering, factual knowledge memorization analysis",No / machine labelled,"Mix OG, External",Wikipedia + author-written templates,Not applicable,Not applicable,Not applicable,Formal instructions,No information,No information,No information,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,14k questions,Cover factual information in the long tail that might have been missed in popular QA datasets,Wikipedia,No information,No information,"(Subject, Relation, Object) triples converted via templates to QA format.",Designed for isolating factual memorization ability based on entity popularity and relation type.,Yes,,,
SingleEQ,10.1162/tacl_a_00160,1766,ACL,No,Single-equation algebra word problem solving,No / machine labelled,Not Labelled,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Single equations with varying length,"Selected to span various templates and difficulty levels, from public math resources.","http://math-aids.com, http: //k5learning.com, and http://ixl.com websites and a subset of the data from Kushman et al. (2014)",No information,No information,Each problem mapped to a valid equation tree that solves to the known answer.,Supports structured prediction from text spans to equation trees.,Yes,,,
2WikiMultiHopQA,10.18653/v1/2020.coling-main.580,195,ACL,No,Multi-hop question answering,No / machine labelled,"Mix OG, External",Authors + Wikidata + Wikipedia,Not applicable,Not applicable,Not applicable,Formal instructions,Not applicable,No information,No information,1,Not applicable,Not applicable,Not applicable,No information,Not applicable,Not applicable,Wikipedia summaries and Wikidata triples,"Ensures diversity of multi-hop reasoning via types: comparison, inference, compositional, bridge-comparison.",Wikipedia and Wikidata,No information,No information,"QA pair with answer span, sentence-level facts, and evidence triples.",Supports explainable reasoning with structured and unstructured components.,Yes,,,
ASDiv,10.18653/v1/2020.acl-main.92,4721,ACL,No,Math word problem solving,Yes for all,OG,Master-degree research assistant,Not applicable,Money,Some training,Formal instructions,Has a background in automatic MWP solving,1,1,1,No,Not applicable,Not applicable,No,Not applicable,Not applicable,"Diverse school-level MWPs across arithmetic, algebraic, and domain-specific types",Designed to reflect the true diversity of elementary math curricula.,28 educational websites,No information,No information,"Problem type, equation, numeric answer, and grade level.",Designed to reflect mathematical structure and linguistic variation.,"Yes, but broken",,,
WritingPrompts,10.18653/v1/P18-1082,176,ACL,No,Story generation,No / machine labelled,Not Labelled,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable ,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Human generated stories paired with writing prompts from an online forum,"Selected to reflect open-domain, creative storytelling scenarios.",Reddit's WritingPrompts forum,No information,No information,Promt - story pair structure,No information,Yes,,,
HKU-IS,10.1109/CVPR.2015.7299184,899,AAAI,No,Visual saliency detection,Yes for all,OG,No information,Unknown,No information,No information,No information,No information,3,3,3,"Yes, for all",Quantitative,Majority,No information,Yes,Custom metric,No information,No information,No information,No information,No information,Yes,No information,"Yes, but broken",,,
LaSOT,10.1109/CVPR.2019.00552,835,AAAI,No,Large scale single object tracking,Yes for all,OG,PhD students and volunteers,Not applicable,Unsure,No information,Some Instructions,No information,"""Several PhD students and about 10 volunteers""",Max. 2,1,"Yes, for some",Qualitative,PhD students correct the volunteer annotation,Yes,No information,No information,Videos of a wide range of objects in diverse contexts,To have a diversified collection of videos,YouTube,"Yes, 1,400","1,400 is large scale",Yes,No information,"Yes, but broken",,,
SPAQ,10.1109/CVPR42600.2020.00373,222,AAAI,No,Image quality assessment,Yes for all,OG,No information,Unknown,No information,Some training,Formal instructions,Subjects were required to have normal or corrected-to-normal visual acuity with correct color vision,600,Average of 16.76,15,"Yes, for all",Quantitative,Average,No information,Yes,SRCC and PLCC,Images taken by smartphones,To obtain realistic image distortions,Images manually taken by 66 smartphones,No information,No information,Yes,No information,Yes,,"GitHub: https://github.com/h4nwei/SPAQ, Supplementary material: https://openaccess.thecvf.com/content_CVPR_2020/supplemental/Fang_Perceptual_Quality_Assessment_CVPR_2020_supplemental.pdf",
DARK FACE,10.1109/TIP.2020.2981922,1830,AAAI,No,Face detection,Yes for all,OG,No information,Unknown,No information,No information,Some Instructions,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,Images of busy streets in Beijing,"To capture ""realistic poor-visibility environments with real image artifacts""",Digital SLR cameras,"Yes, 10,000",No information,Yes,No information,No,,,
mit indoor scenes,10.1109/CVPRW.2009.5206537 ,3122,TPAMI,No,Indoor scene classification,Yes for all,OG,Authors + annotators,Unknown,No information,No information,Formal instructions,No information,No information,1,1,No,Not applicable,Not applicable,No information,Not applicable,Not applicable,15620 indoor scene images across 67 categories,Wide range of real-world indoor environments,"Google, Atlavista, Flickr",Yes,Training / testing of high-variance indoor categories; fixed 80 train / 20 test,Yes,Categories selected to span diverse indoor scenes; schema based on scene prototypes,No,One annotator for ROI (region of interest); category labels assigned manually based on curated categories,,
oxford flowers 102,10.1109/ICVGIP.2008.47,11781,TPAMI,No,Flower species classification,Yes for all,OG,Expert human annotators,Unknown,No information,No information,Some Instructions,"Experts were mentioned, implying intentional selection for domain knowledge.",At least three named,No information,No information,No information,No information,No information,No information,No information,No information,"8189 images, 103 flower categories; each class has 40-250 images",Represent flowers commonly occuring in the UK,Web + photos taken by authors,Yes,Balance class representation and capture large between class similarity.,Yes,Natural taxonomy; intended for fine-grained categorization,Yes,Labels are expert-assigned to match specific flower species.,,
stanford 40 actions,10.1109/ICCV.2011.6126386,9055,TPAMI,No,Human action classification,Yes for all,OG,Authors,Unknown,No information,No information,Some Instructions,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,9532 images; 40 actions,Diverse coverage of common daily actions,"Google, Bing, Flickr","Yes, 180-300 images per class; 100 used for training",Ensure diversity and support generalization,Actions defined as verb-based categories,"Verbs, objects used to support structured, interpretable action representation.",Yes,"No specific mention of instructions, but task well defined.",,
imagenet-real,10.48550/arXiv.2006.07159,4820,TPAMI,No,Image classification,Yes for all,External,"Crowdsourced human annotation, guided by predictions from ensemble models",Generic Skill Based,Money,Some training,Formal instructions,MTurk workers selected based on prior performance,~50 MTurk workers,5,3 out of 5,"Yes, for all",Quantitative,Majority vote,No information,Yes,Fleiss' Kappa,50000 images (same as ImageNet 2012),Imagenet 2012 validation set used as a benchmark; improved label quality.,ImageNet 2012,Yes,Full re-annotation of the fixed 50k image validation set,Yes,"Aim to capture all valid labels per image; m,ulti-label",Yes,ReaL improves quality for the ImageNet validation set; each image could be assigned multiple valid class labels.,,
pascal voc 2010,10.1007/s11263-009-0275-4,11194,TPAMI,Yes,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
UHD-LOL,10.1609/aaai.v37i3.25364,200,AAAI,No,Low light enhancement of UHD images,No / machine labelled,Not Labelled,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Images of various scenes,No information,UHDSR4K and UHDSR8K datasets,No information,No information,Not applicable,Not applicable,Yes,,"GitHub: https://github.com/TaoWangzj/LLFormer, Project website: https://taowangzj.github.io/projects/LLFormer/",
BIKECHI,10.1145/3474717.3483923,192,AAAI,No,Traffic prediction,No / machine labelled,Not Labelled,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Bike-sharing rides in Chicago,No information,Divvy bikes,No information,No information,Not applicable,Not applicable,Yes,It was very difficult to find the dataset description,Data is taken from https://divvybikes.com/system-data,
NYTaxi,N/A,192,AAAI,No,Traffic prediction,No / machine labelled,Not Labelled,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Taxi trips in NYC,No information,Trip tracking technology in taxis and a self-reported survey of the passenger count,No information,No information,Not applicable,Not applicable,Yes,,Data is taken from https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page,
ptb,N/A,97526,NeurIPS,No,"Language processing, speech recognition, linguistics",Yes for all,External,"Brown Corpus, but discarded redundant labels",Generic Skill Based,Money,Some training,Formal instructions,"Graduate studies in linguistics, so domain knowledge",4,"Not precisely mentioned, but at least 2",1,"Yes, for all",Qualitative,Discussion,Yes,Yes,Percent disagreement,"Sentences from multiple sources, with a total of 4.8M words","Broader applicability, showing how linguistic phenomena occur naturally","Both written and spoken sources (manuals, transcribed podcasts, fiction and non-fiction books, etc)",No information,Aimed for a large dataset,"Yes, from external source",Used in other datasets from the same domain,No,"Mixed procedure between machine annotation and human annotation, but human labellers contributed to all items. really nice paper, the reason why there is no link is bcs it was made in the 90's and they have it on CD :)",,
imagenet fall 2009,N/A,85220,NeurIPS,Yes,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
alpaca,N/A,791,NeurIPS,No,Instruction demonstrations for LLMS,No / machine labelled,External,"Self-instruct paper for the seed set, machine-generated for the rest",Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,52k instruction demonstrations,Replicating instruction following capabilities of commercial models with public resources,Generated with text-davinci-003 (openAI),No information,Large dataset but cheap to produce with OpenAI API,Not applicable,Not applicable,Yes,"Very basic synthetic dataset, i don't know for now if it's weak or not",Dataset accesible here,
webis-tldr-17,10.18653/v1/W17-4508,5326,NeurIPS,No,Text summarisation,Unsure,OG,Authors,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Unsure,Unsure,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,4 million Reddit posts that contain a TL;DR,"Datasets for this task usually contain news articles, so they wanted another ""genre"" that would have non-professional text","Reddit, through pushshift.io (2006-2016), filtered to contain summary and not made by a bot",No information,"They say that you need a large dataset for this task, they don't really argue why",Yes,"Simple text split between title (if applicable), body and summary","Yes, but broken","The procedure is pretty well explained, they also made some rules for the posts that ended up in the corpus",,
birdsnap,10.1109/CVPR.2014.259,7170,NeurIPS,No,Bird species classification,Yes for all,OG,Authors,Unknown,Money,No information,Some Instructions,"MTurk workers, no specific criteria mentioned",No information,"No precise information, but they say ""multiple""",No information,"Yes, for all",Other,Discarded inconsistent labels,No,No,Not applicable,49829 images of the most common 500 birds in North America,Region-specific usability,"Flickr, other unspecified sources if Flickr did not yield enough","Yes, 50000, 100 for each species",No information,Yes,"Capturing the birds' body parts, sex, estimated age etc. Not explicit but discussed within the advantages of the dataset","Yes, but broken","Re. training / instructions, they technically received a guide and some instructions but i'm not sure about the ""formal"" part. There technically is a link, but it directs to a brand that sells bird feeders, lol",,
sun397,10.1109/CVPR.2010.5539970,16601,NeurIPS,No,Scene categorisation / recognition,Yes for all,"Mix OG, External",nouns that describe scenes from WordNet (majority of labels) + some others from the authors,Unknown,No information,No information,Some Instructions,No information,No information,No information,No information ,No information,No information,No information,No information,No information,No information,130k images from 829 scene categories (only 397 are well-sampled),Wide range of scenes,Same as Tiny Images (10.1109/TPAMI.2008.128) - multiple web sources,No information,"Visually representative, diverse for each scene",Yes,Wanted to be as exhaustive with the number of scenes as possible,"Yes, but broken","Link directs to Places dataset, but the Sun dataset is actually available online",,
commonsenseqa,10.18653/v1/N19-1421,6180,NeurIPS,No,Question answering with prior knowledge,Yes for all,OG,Crowdworkers (annotators),Project Specific,Money,No information,Formal instructions,"Some annotators generated the questions and others verified them, they were filtered by the percentage of questions that were well-reviewed by the verifiers","122 for the questions, no information on the verifiers","1 for questions, 2 for verification",Unsure,"Yes, for all",Quantitative,There was overlap only with the verifiers. They discarded questions that could not be answered correctly by them.,No,No,Not applicable,"12k questions that require common sense, with 5 MC answers each, one of them correct","Aimed to create questions that require some common sense knowledge that humans generally have, beyond word association",Generated by crowdworkers,No,No information,"Unsure, but somewhat I would say yes","Wanted 4 wrong answers and 1 correct per question, but all the choices had to require common sense knowledge",Yes,Really interesting read,Dataset available here,
gsm8k,10.48550/arXiv.2110.14168,6582,NeurIPS,No,Mathematical reasoning,Yes for all,OG,Crowdworkers (annotators),Unknown,Money,No information,Some Instructions,UpWork and Surge AI workers,No information,No information,No information,"Yes, for all",Other,"2 agreement checks: first was quantitative, second no information (they mention thay repaired or discarded problems in the first check and they most likely kept them in the second)",No,Yes,"Percent disagreement (ONLY for the secind round, no info on the first)",8.5k grade school math problems,"Problems with ""moderate difficulty"" that require some steps to solve, with high language diversity",Generated by crowdworkers,No,No information,Yes,"Problem - steps - solution for the train set, problem - solution for the test set, they generated some examples with GPT3 to show annotators",Yes,"From a 22-page DATASET paper, only 2 pages talk about this process, and there were barely any arguments, kind of disappointing",Dataset available here,
imdb-,N/A,1915,NeurIPS,No,Sentiment analysis,No / machine labelled,External,"""Following previous work on polarity classification"", they don't mention any source",Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,No,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,"50k IMDB reviews, polarised","Reviews from IMDB which are also accompanied by a mark are a good source for sentiment analysis, also the fact that they are informal and made by real people for a real thing",IMDB,Yes,"They do not explicitly say it was decided a priori, but implicitly it kind of leads to that. Large DS to limit word based association.",Yes,"Polarised for binary sentiment classificaton, wanted to exclude ""neutral"" reviews, so negative for <=4, positive for >= 7","Yes, but broken",,,
berkeleyparser,10.48550/arXiv.1412.7449,83482,NeurIPS,No,syntactic parsing,No / machine labelled,External,BerkeleyParser (the model) and other corpora that were human-annotated,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,No,Not applicable,Not applicable,Not applicable,Not applicable,Not applicable,~7M sentences with a syntactic parse tree,Fit for task,News articles from the internet + 90k sentences from other corpora,No information,Wanted a large DS because they said models don't perform well on smaller datasets,Yes,From other corpora for the same task,No,"Very meh approach to it, not much argumentation, a lot of information unclear",,
books1,10.48550/arXiv.2005.14165,19613,NeurIPS,No,Training,Unknown,No information,No information,Unknown,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,Books,Information diversity when training GPT3,Internet,No information,No information,No information,No information,No,"This is an intrenal DS of OpenAI, this is all the information from the paper :|",,
books2,10.48550/arXiv.2005.14165,19613,NeurIPS,No,Training,Unknown,No information,No information,Unknown,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,No information,Books,Information diversity when training GPT3,Internet,No information,No information,No information,No information,No,"This is an intrenal DS of OpenAI, this is all the information from the paper :|",,